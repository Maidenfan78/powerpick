# Prediction Engine Spec – Phase 4 (Implementation Sprint 3)

## ⚡ Summary

This document formalises the **lottery‑number prediction subsystem** that ships in Phase 4. It captures the current TypeScript implementation, highlights gaps, and outlines the minimal extensions required to satisfy the *“Better Predictions”* exit criterion.

> **Status:** Draft v0.1 — July 1 2025

---

## 1  Scope & Objectives

|  Goal                       | Concrete Outcome                                                                        |
| --------------------------- | --------------------------------------------------------------------------------------- |
| **G1** Hot/Cold analytics   | Keep Supabase table `hot_cold_numbers` up‑to‑date via nightly job.                      |
| **G2** Bell‑curve balancing | Restrict each suggested set’s total sum to the busiest 70 % of the theoretical range.   |
| **G3** User sliders         | Allow clients to bias towards hot or cold numbers with a *single* ratio slider (0 – 1). |
| **G4** Extensible weighting | Inject external per‑ball weight vectors generated by a Python job.                      |
| **G5** Test coverage        | ≥ 90 % branch coverage over `src/lib/{generator,hotCold}.ts`.                           |

Out‑of‑scope for Phase 4: neural nets, reinforcement learning, or live server‑side model inference. These remain Phase 6 topics.

---

## 2  Current Implementation (Audit)

|  File                    | Purpose                                                                                                                                                                                            | Notes |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----- |
| `src/lib/generator.ts`   | `generateSet()` picks numbers with weighted sampling, retries until the sum is within ±35 % of the mean **(≈70 % bell‑curve window)**. Accepts `hotNumbers`, `coldNumbers`, and scalar `hotRatio`. |       |
| `src/lib/hotCold.ts`     | `calculateHotColdNumbers()` counts frequencies across historical draws and returns the top/bottom *n %* as hot/cold.                                                                               |       |
| `src/lib/syncDraws.ts`   | CLI script: pulls CSVs, populates `draws` and `draw_results`.                                                                                                                                      |       |
| `src/lib/syncHotCold.ts` | CLI script: queries `draw_results`, computes hot/cold sets, upserts into `hot_cold_numbers`.                                                                                                       |       |

### Strengths

* **Deterministic inputs** → reproducible with fixed random seed.
* **Pure functions** – easy to unit‑test in isolation.
* **Bell‑curve filter** already implemented, passing ✅.

### Weaknesses / Gaps

* Only supports one “main” ball group — Powerball, EuroMillions Stars, etc. are ignored.
* `hotRatio` is linear; exponential weight option would give subtler control.
* Bell‑curve window hard‑coded at ±35 %; cannot be tuned per game.
* No ML‑based weight file ingestion yet.
* Lacks Jest tests and type‑level guards.

---

## 3  Data Flow

```text
CSV → syncDraws.ts   ─┐
                      │   draw_results (Supabase)
                      ├──────────────┐
Scheduler             │              │
(nightly cron)        ▼              │
               syncHotCold.ts        │
                      │              │
                      ▼              │
            hot_cold_numbers (Supabase)
                      │              ▲
                      └──────────────┘
                  client app fetches
                    → generator.ts → suggested sets
```

> **Note:** Weight files produced by the Python pipeline (see §4) will be stored in `assets/weights/` and cached client‑side.

---

## 4  Planned Enhancements

|  ID | Description                                                                                |  Owner |  ETA   |
| --- | ------------------------------------------------------------------------------------------ | ------ | ------ |
|  E1 | **Parameterise bell‑curve window** (`windowPct = 0.70` default).                           | TS     | 08‑Jul |
|  E2 | **Multi‑group generation** (main, supplementary, powerball).                               | TS     | 12‑Jul |
|  E3 | **Python weighting job** — decay‑adjusted frequency model → outputs `weights/{game}.json`. | Py     | 15‑Jul |
|  E4 | **Weight ingestion layer** in `generator.ts` (fallbacks if file missing).                  | TS     | 17‑Jul |
|  E5 | **Jest test‑suite + CI badge update**.                                                     | TS     | 19‑Jul |

---

## 5  API Contracts

### 5.1 Weight File (`assets/weights/<game>.json`)

```jsonc
{
  "generated_at": "2025-07-15T03:24:18Z",
  "decay_half_life": 120,         // draws
  "weights": [0, 1.05, 0.97, ...] // 1‑indexed length = maxNumber
}
```

### 5.2 Generator Function

```ts
interface GenerateOptions {
  /** Hot→Cold bias (0=ignore hot/cold, 1=strongly favour hot) */
  hotRatio?: number;
  /** Override bell‑curve window width (0.5 – 0.9) */
  windowPct?: number;
}

type BallSet = number[];

interface Prediction {
  main: BallSet;
  supplementary?: BallSet;
  powerball?: number;
  sum: number;
}

function generateNumbers(gameId: string, opts?: GenerateOptions): Prediction;
```

---

## 6  Testing Strategy

* **Unit Tests** — `generateSet()` edge‑cases, bell‑curve bounds, hot/cold weighting maths.
* **Snapshot Tests** — deterministic output with fixed PRNG seed.
* **Integration Tests** — mock Supabase calls, ensure end‑to‑end generation honors DB hot/cold.

CI gate: `yarn test` must stay ≤ 2 s on local dev machine.

---

## 7  Risks & Mitigations

|  Risk                                             | Impact           | Mitigation                                              |
| ------------------------------------------------- | ---------------- | ------------------------------------------------------- |
| **R1** Weight files go stale                      | Poor suggestions | Sync Python job daily; log SHA in client.               |
| **R2** Randomness perceived as “bug”              | Player distrust  | Show disclaimer + seed info in debug panel.             |
| **R3** Regulatory pressure on “prediction” claims | App rejected     | Ensure copy avoids guaranteed outcomes; add legal note. |

---

## 8  Open Questions

1. Where should weight JSONs live in production — Supabase storage bucket vs. version‑controlled assets?
2. How often should we decay historical draws (fixed half‑life or adaptive)?
3. Do we need separate sliders for main vs. supplementary balls?
4. Should ticker events (e.g., jackpot rollovers) influence the weighting schedule?

---

## 9  Next Actions

1. **Approve spec** in PR #???
2. Begin `E1` implementation branch `feat/ml-bellcurve-param`.
3. Spin up Airflow (or cron) task for Python weight generation.
4. Draft Jest tests and add to CI.

---

> *Document owner:* **ML/Prediction Engineer**
>
> *Last updated:* 2025‑07‑01
